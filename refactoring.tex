\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage[scaled]{helvet}
\usepackage[T1]{fontenc}
\usepackage{geometry}
 \geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{epsfig}
\usepackage{tikz} 
\usepackage{graphicx}
\usepackage{stackengine}
\usepackage{times}
\usepackage{url}

%\usepackage[pagebackref=true,breaklinks=true,colorlinks,bookmarks=false,linkcolor=black,citecolor=black]{hyperref}
\usepackage{hyperref}

\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

\newcommand\todo[1]{\textcolor{red}{ToDo: #1}}
\newcommand\note[1]{\textcolor{red}{Note: #1}}

\newcommand\email[1]{\small{\href{mailto:#1}{\color{black}{\nolinkurl{#1}}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
\begin{document}

%%%%%%%%% TITLE
\title{Refactoring in epistemic and artistic practice}

\author{Dennis Scheiba\\
\email{dennis.scheiba@rsh-duesseldorf.de}\\
Robert Schumann Hochschule Düsseldorf - Institut für Musik und Medien\\
}
\maketitle

\begin{abstract}

\begin{quote}
Refactoring has no singleton purpose and although it is arguably important and performed everyday in applied computer science it is difficult to give a precise definition of the necessities for such a process.
The struggle between intuition, generalization, simplification and complexity is where refactoring resides.
Attached to this method is always the evaluation of a trade-off, between opening possibilities which at the same time makes other possibilities impossible.

Revisiting the work of oneself or others is not just important in software development but also within the context of science, society, law and art.
In this paper we therefore want to discover how the practice of refactoring is present in a variety of domains and inspect implementations, implication and practices which then could be adopted and transformed among domains, therefore refactoring the refactoring.
\end{quote}
\end{abstract}

\vspace{-1em}

\section{Modularization}

Refactoring is a crucial and daily practice in software development, yet it is difficult to define a precise goal to this process.
One could argue that refactoring is a re-evaluation and modification of existing modularization in the context of what the status quo is and projecting what this status quo could and should be in the future.

The proclaimed modularization should allow us to separate an existing complex subject into distinctive yet not fully independent sub discretizations which then can be re-adapted on a per-context basis.
For instance mathematics, which is often labeled as a \textit{auxillary science}, has its goal to form such universal statements which can be re-adapted in various contexts.
This should be motivation enough to stay in this transformation area which allows us to inspect the foundations of our believes and allows us to not just handle complexity but allows us to inspect complexity within complexity itself.
Therefore we can see refactoring as an epistemic gesture which tells us about our work, our ideological foundations and our projections into a future.

\subsection{Modularization of references}

Yet we must discuss if modularization actually exists as well as abstraction itself which should be doubted at first as well.

\todo{This needs to be written, want to include \cite{Teil_Latour_1995} and \cite{Kircz_1998} here}

\todo{include the difference(?) between modularization and referential}

\subsection{Refactoring in Software}

There seems to be a common conception of what a \textit{good} written software is and what is not.
This \textit{quality} can be evaluated on multiple categories, but not limited to, such as

\begin{itemize}
    \itemsep0em
    \item Number of Bugs
    \item Features
    \item Usability
    \item Catholicity
    \item License
\end{itemize}

Yet it is important to comprehend that each of these metrics are rarely independent of each other.
% was soll ein bug sein?
An increase of features is likely to also increase the number of bugs as it introduces more and more edge cases whose combinations can lead to bugs.
Projects like \textit{SonarQube} gives us the promise to quantify the quality of such source code based on certain criteria.
Yet we ask ourselves why such a service is limited to the domain of source code for software and is not used in other domains where an ambiguity between intention and error is possible which is demonstrated by such infamous quotes as 
% To allow a re-transformation of such a field refactoring.
%There are also certainly bugs which can not be observed on such a low level of analysis as the infamous quote
\begin{quote}
    is this a bug or a feature?
\end{quote}
%demonstrates.
This classification and notion of what an error is and what is not therefore relies only on an implicit context.
This implicit understanding can lead to frictions which then can be resolved by discussing the explicit understanding of the complex.

This distinction between malfunction and function is not limited to the domain of software as demonstrated by another quote
\begin{quote}
    % ist das kunst oder kann das weg
    \todo{Ist das Kunst oder kann das weg}
\end{quote}
which probably finds it motivation by the infamous \textit{Fettecke} by Joseph Beuys, in which also the embedded context of an artefact is important.
An obvious domain of art which plays and enables to re-contextualization and emancipation of errors is glitch art but has recently also developed beyond this mere aesthetic to an conception of error within art \cite{Schubert_2019}.

\subsection{Elastic coupling of possibilities}

Modularization in software promises an isolation, encapsulation and restructuring of a given complex and over the years certain patterns emerged in which software is build to enforce these particular structures.
Common techniques are called design principles, paradigms or techniques and is one of the motivations and distinctions to create different programming languages.
Do we talk to everyone who can talk, like in duck typing, or do we only talk to a certain kind of entities, like in static typing?
We clearly see that those patterns are loaded with ideology and it is interesting to discuss how much influence certain ideologies have on certain programming paradigms.

Yet in order to allow a re-contextualization of our program we need to provide an API (Application Programming Interface) which defines the communication between components and provides also allows to create a boundary between different concepts and principles, allowing us to leave the nucellus of restrictions of certain concepts.
This terra incognita can be within same programming language, between programs, between multiple computers or also between human and machine and its design is crucial to the idea of refactoring. 
% use turing completeness as a foundation here?

Although we yet omitted one crucial statement which builds the foundation for all modularization and transformation in the domain of software which is the common ground of turing completeness.
Turing completeness gives us the promise that if a machine can perform a certain set of instructions it can operate any program which is turing complete and this implies that any any turing machine can simulate any other turing machine.
This machine can be a hardware machine or a software program as well.
% explain what this means
Yet it is false to assume that turing completeness allows us to do anything at all time - we do not use Power Point as an audio workstation \todo{note that powerpoint is indeed turing complete} and don't use GIMP to cut audio files simply because the intentions of each program is aimed at a different purpose.
While they all rely on a coordination of voltages in a circuit based upon its environmental input we need to build barriers and tame the possibilities to get something constructive out of it.
% this is the same as high level language ?
% This means that all programs which are Turing complete are interchangeable but in order to build complex programs we need to tame the possibilities.
By deciding what is and what is not possible within our program we allow the program to exist and build contained modules, albeit this reduction of possibilities can be achieved on different levels of operation.

Art often relies on an universal language of communication as well as it tries to evoke a resonance within a biological circuit with the means of sensorial evaluation.
As humans are at all times exposed to sensorial input we also try to tame this input to allow ourselves to focus and overcome a first perception, reconstructing our understanding by revisiting the known and adapting to the input, allowing ourselves to project ideas into the future.
Therefore modularization and a coupling of these fragments can not only be observed in computer science but also can be seen in the domain of arts - be it as trivial as a sample or a quotation or as complex as an untraceable influence within the artwork or the context of its culture.
This seesaw of references within culture can also be regarded as a rhizome and is therefore similar to the references within the source code of a program which is neither by human neither by machine read from top to bottom but instead creates something like a self-supporting network of references which at the same time still offers a clear entry point for hallucinations within the restricted realm of possibilities.

We also find a similarity within the paradigms and design principles of art which is nowadays (at least by institutions) still separated into fine arts, performing arts, music and theoretical discourse.
Within each of these contexts we also find cross-contaminations between those subjects, so just as an API allow us to cross barriers of paradigms we can also see these acts of building bridges by the referential feedback loop within art.

% Also the human as a social being can not escape exposure to its culture, therefore all creations could be seen as reactions to the input we have received.

\subsection{Promises}

In order to allow modularization it is important to be transparent, open, critical and open to changes in order to gain a concept of better understanding.
This is closely tied to the concept of a promise because there needs to be a common trust when transferring concepts between domains that there is nothing lost in translation.

\todo{More to come? Want to include something out of \cite{bratton_stack_2015}here.}

% \subsection{Modularization in science}

\section{Refactoring errors}

\subsection{Refactoring a black box}

\todo{Refactoring itself could be a black box b/c often enough only the intenal mechanism gets re-wired and no new features get added?}

\todo{Can we only refactor stuff we understand? What about neural networks.}

\todo{there are neural networks which evaluate aesthetic characteristics but not on a hard rule set?}

\subsection{Refactoring expectations}

\todo{Some satitistical analysis of linux kernel commits regarding errors and refactoring?}

\todo{The drug trip as a mind refactoring?}


\section{Rearranging sound}

As this paper is written on a music academy we want to inspect this principle upon the domain of sound as well. 

\todo{Would really love to take the text as a springboard to a composition/sonic concept but am currently a bit lost here. Would really like to cite some ideas of \cite{Xenakis_1992} here as I am currently into his ideas}

\subsection{Dependency Hell}

\bibliographystyle{alpha}
\bibliography{references}

\end{document}